{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca401210-2021-41ad-ba51-a2c02fbf01b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 14:49:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-3-9.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark_SQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe78d9b9f40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ss = SparkSession.builder.appName('Spark_SQL').getOrCreate()\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15751cf3-8681-447c-88b3-f860c53b345f",
   "metadata": {},
   "source": [
    "| **특징**              | **`ss.read.csv()`**                     | **`ss.read.format('csv').load()`**            |\n",
    "|-----------------------|------------------------------------------|-----------------------------------------------|\n",
    "| **목적**              | CSV 파일 읽기에 특화                    | 다양한 파일 형식을 처리하기 위한 일반적 방식 |\n",
    "| **가독성**            | 간결하고 직관적                         | 다소 장황                                    |\n",
    "| **유연성**            | CSV 파일에 한정                         | 다양한 데이터 형식을 지원                     |\n",
    "| **옵션 설정 방법**     | 메서드 인자로 직접 전달                  | `.option()` 또는 `load()` 인자로 설정         |\n",
    "| **다른 파일 형식 확장**| 불가능                                  | 가능                                         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0403ca74-ee6c-4396-86a0-e7479477b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df = ss.read.csv('data/emp.csv', header = True)\n",
    "# 큰 차이없음\n",
    "# emp_df2 = ss.read.format('csv').load('data/emp.csv', header = True)\n",
    "\n",
    "dept_df = ss.read.csv('data/dept.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33ac86ac-ea0a-40a2-affb-301fb5a502c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: string (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: string (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: string (nullable = true)\n",
      " |-- comm: string (nullable = true)\n",
      " |-- deptno: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- deptno: string (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_df.printSchema(), dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea2f2b9e-7b96-4d53-8380-f4d9d6e877c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.createOrReplaceTempView('emp_tmp')\n",
    "dept_df.createOrReplaceTempView('dept_tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ca6ae42-5a0b-4de3-bac5-9e46cc4b8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뷰에서 조인\n",
    "ss.sql('''\n",
    "        select\n",
    "            A.*\n",
    "            , B.*\n",
    "        from emp_tmp as A\n",
    "        \n",
    "        inner join dept_tmp as B\n",
    "        on A.deptno = B.deptno\n",
    "        ''')\\\n",
    ".createOrReplaceTempView('join_view')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4576c550-ec68-4df5-8622-773f74c84f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ss.sql('''\n",
    "select *\n",
    "from join_view\n",
    "where upper(loc) = upper('new york')\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac9567ea-3201-4f15-88b5-0199bfeaf1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서 위치가 NEW YORK인 직원 목록\n",
    "\n",
    "ss.sql('''\n",
    "select * from emp_tmp\n",
    "where deptno = (\n",
    "    select deptno from dept_tmp\n",
    "    where loc = 'NEW YORK'\n",
    "    )\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d40aaa6-ccf3-46cd-8afb-177cde0b97c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [deptno#433], [deptno#458], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(deptno#433)\n",
      ":  +- FileScan csv [empno#426,ename#427,job#428,mgr#429,hiredate#430,sal#431,comm#432,deptno#433] Batched: false, DataFilters: [isnotnull(deptno#433)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab17/git/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:string,ename:string,job:string,mgr:string,hiredate:string,sal:string,comm:string,dep...\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [id=#859]\n",
      "   +- *(1) Filter ((isnotnull(loc#460) AND (upper(loc#460) = NEW YORK)) AND isnotnull(deptno#458))\n",
      "      +- FileScan csv [deptno#458,dname#459,loc#460] Batched: false, DataFilters: [isnotnull(loc#460), (upper(loc#460) = NEW YORK), isnotnull(deptno#458)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab17/git/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), IsNotNull(deptno)], ReadSchema: struct<deptno:string,dname:string,loc:string>\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(deptno#433) AND (deptno#433 = Subquery scalar-subquery#1455, [id=#878]))\n",
      ":  +- Subquery scalar-subquery#1455, [id=#878]\n",
      ":     +- *(1) Project [deptno#458]\n",
      ":        +- *(1) Filter (isnotnull(loc#460) AND (loc#460 = NEW YORK))\n",
      ":           +- FileScan csv [deptno#458,loc#460] Batched: false, DataFilters: [isnotnull(loc#460), (loc#460 = NEW YORK)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab17/git/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK)], ReadSchema: struct<deptno:string,loc:string>\n",
      "+- FileScan csv [empno#426,ename#427,job#428,mgr#429,hiredate#430,sal#431,comm#432,deptno#433] Batched: false, DataFilters: [isnotnull(deptno#433)], Format: CSV, Location: InMemoryFileIndex[file:/home/lab17/git/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:string,ename:string,job:string,mgr:string,hiredate:string,sal:string,comm:string,dep...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case 1 - 조인 사용\n",
    "ss.sql('''\n",
    "select *\n",
    "from join_view\n",
    "where upper(loc) = upper('new york')\n",
    "''').explain()\n",
    "\n",
    "\n",
    "# case 2 - 서브 쿼리 사용\n",
    "# 서브 쿼리가 이 상황에서는 효율적임 왜냐, 컬럼을 이미 좁혀서 가져왔기 때문\n",
    "ss.sql('''\n",
    "select * from emp_tmp\n",
    "where deptno = (\n",
    "    select deptno from dept_tmp\n",
    "    where loc = 'NEW YORK'\n",
    "    )\n",
    "''').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61681a84-57ae-4b62-99af-5cafbec0cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
