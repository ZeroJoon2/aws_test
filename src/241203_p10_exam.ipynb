{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb10c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 10:27:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark 세션을 만듦\n",
    "# 이름을 지정하면 충돌이 안남\n",
    "spark = SparkSession.builder.appName('PySpark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2bff802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark 세션의 모드 확인하기\n",
    "spark.sparkContext.master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf23322",
   "metadata": {},
   "source": [
    "### RDD 객체 사용\n",
    "spark의 기본 데이터 형식  \n",
    "python에서 리스트 생성하듯이 하면 되지만, 분산 데이터 객체이기에, session에 등록해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f61f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5]) #paralleize : 병렬임. 하나가 깨져도 다른 곳에서 작동하는 느낌\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69f08dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2d19d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd = rdd.map( lambda x : x*x )\n",
    "squared_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7eab975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squared_rdd.collect() #collect는 sparkUI에 job에 뜸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cccbc6",
   "metadata": {},
   "source": [
    "### 데이터 프레임 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8bfd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Value: bigint]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Alice', 1), ('Bob',2 ), ('Charlie',3)]\n",
    "df = spark.createDataFrame(data, ['Name', 'Value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a061e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Alice|    1|\n",
      "|    Bob|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#데이터 프레임에서 데이터를 보려면 show\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8471e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Value > 2').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e5e793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Bob|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Name == 'Bob'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0be90e",
   "metadata": {},
   "source": [
    "### RDBMS 데이터(테이블)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1a72223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('tbpeople') #tbpeople이라는 테이블을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4307e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sql = 'SELECT * FROM tbpeople WHERE Value > 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20ff36f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(select_sql).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b4270",
   "metadata": {},
   "source": [
    "### 데이터프레임 생성 -> select로 DF를 꺼내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfe635e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "|  최|  100|\n",
      "|  영|  200|\n",
      "|  준|  300|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = [('최', 100), ('영',200 ), ('준',300)]\n",
    "df2 = spark.createDataFrame(data2, ['Name', 'Value'])\n",
    "\n",
    "df2.createOrReplaceTempView('test_df2')\n",
    "\n",
    "spark.sql('select * from test_df2').show() #sql 딱히 대소문자 관계 없음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26c8cae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2350da",
   "metadata": {},
   "source": [
    "### MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aa7e862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e45f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|    Bob| 30|\n",
      "|Charlie| 30|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('Alice', 25), ('Bob', 30), ('Charlie', 30)], ['name', 'age'] )\n",
    "\n",
    "df_filtered = df.filter(df.age> 28)\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae2e25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['age'], outputCol = 'features')\n",
    "vector_df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5b73cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/03 11:29:42 WARN Instrumentation: [b90aba44] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/12/03 11:29:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/12/03 11:29:43 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/12/03 11:29:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/12/03 11:29:43 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'age')\n",
    "model = lr.fit(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "02908c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+----------+\n",
      "|   name|age|features|prediction|\n",
      "+-------+---+--------+----------+\n",
      "|  Alice| 25|  [25.0]|      25.0|\n",
      "|    Bob| 30|  [30.0]|      30.0|\n",
      "|Charlie| 30|  [30.0]|      30.0|\n",
      "+-------+---+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(vector_df)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cd954a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark 종료해줌\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44400ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f834240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29dfd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ef545e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.get_dataset_names()\n",
    "sns_df = sns.load_dataset('anscombe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f85271a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'createOrReplaceTempView'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3454/101894557.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sns_sample_table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mselect_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'select * from data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_sql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'createOrReplaceTempView'"
     ]
    }
   ],
   "source": [
    "sns_df.createOrReplaceTempView('sns_sample_table')\n",
    "select_sql = 'select * from data'\n",
    "spark.sql(select_sql).show()\n",
    "\n",
    "#sns_df는 dataframe이라서 이 방식이 일단 안통하는 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1207eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cacef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152f02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3557e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
